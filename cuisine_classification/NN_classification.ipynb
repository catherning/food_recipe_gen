{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"D:\\\\Documents\\\\food_recipe_gen\\\\recipe_1m_analysis\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = \"D:\\\\Google Drive\\\\Catherning Folder\\\\THU\\\\Thesis\\\\Recipe datasets\\\\scirep-cuisines-detail\"\n",
    "FILE = \"cleaned_data.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(os.path.join(FOLDER_PATH,FILE))\n",
    "df=df.reset_index()\n",
    "df[\"nb_ingr\"]=df[\"ingredients\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'egg': 0,\n",
       " 'yeast': 1,\n",
       " 'wheat': 2,\n",
       " 'milk': 3,\n",
       " 'lard': 4,\n",
       " 'pork': 5,\n",
       " 'carrot': 6,\n",
       " 'pea': 7,\n",
       " 'onion': 8,\n",
       " 'potato': 9,\n",
       " 'maple_syrup': 10,\n",
       " 'almond': 11,\n",
       " 'honey': 12,\n",
       " 'oat': 13,\n",
       " 'date': 14,\n",
       " 'vegetable_oil': 15,\n",
       " 'whole_grain_wheat_flour': 16,\n",
       " 'butter': 17,\n",
       " 'lovage': 18,\n",
       " 'clam': 19,\n",
       " 'thyme': 20,\n",
       " 'black_pepper': 21,\n",
       " 'parsley': 22,\n",
       " 'ginger': 23,\n",
       " 'bay': 24,\n",
       " 'celery': 25,\n",
       " 'cinnamon': 26,\n",
       " 'mustard': 27,\n",
       " 'cane_molasses': 28,\n",
       " 'raisin': 29,\n",
       " 'cream': 30,\n",
       " 'asparagus': 31,\n",
       " 'olive_oil': 32,\n",
       " 'pepper': 33,\n",
       " 'garlic': 34,\n",
       " 'tomato': 35,\n",
       " 'cilantro': 36,\n",
       " 'tea': 37,\n",
       " 'jasmine': 38,\n",
       " 'vegetable': 39,\n",
       " 'brown_rice': 40,\n",
       " 'lemon_juice': 41,\n",
       " 'soy_sauce': 42,\n",
       " 'white_wine': 43,\n",
       " 'chicken': 44,\n",
       " 'vanilla': 45,\n",
       " 'rice': 46,\n",
       " 'mushroom': 47,\n",
       " 'chicken_broth': 48,\n",
       " 'basil': 49,\n",
       " 'porcini': 50,\n",
       " 'mozzarella_cheese': 51,\n",
       " 'tuna': 52,\n",
       " 'lemon': 53,\n",
       " 'beef': 54,\n",
       " 'fish': 55,\n",
       " 'cocoa': 56,\n",
       " 'green_bell_pepper': 57,\n",
       " 'oregano': 58,\n",
       " 'rosemary': 59,\n",
       " 'coffee': 60,\n",
       " 'banana': 61,\n",
       " 'squash': 62,\n",
       " 'egg_noodle': 63,\n",
       " 'bell_pepper': 64,\n",
       " 'cheddar_cheese': 65,\n",
       " 'broccoli': 66,\n",
       " 'cayenne': 67,\n",
       " 'scallion': 68,\n",
       " 'lettuce': 69,\n",
       " 'cucumber': 70,\n",
       " 'cream_cheese': 71,\n",
       " 'melon': 72,\n",
       " 'cranberry': 73,\n",
       " 'peanut': 74,\n",
       " 'nut': 75,\n",
       " 'chickpea': 76,\n",
       " 'yogurt': 77,\n",
       " 'bread': 78,\n",
       " 'tabasco_pepper': 79,\n",
       " 'cod': 80,\n",
       " 'bacon': 81,\n",
       " 'pimento': 82,\n",
       " 'black_tea': 83,\n",
       " 'grapefruit': 84,\n",
       " 'orange_juice': 85,\n",
       " 'pineapple': 86,\n",
       " 'vinegar': 87,\n",
       " 'sesame_oil': 88,\n",
       " 'sake': 89,\n",
       " 'sesame_seed': 90,\n",
       " 'soybean': 91,\n",
       " 'thai_pepper': 92,\n",
       " 'nutmeg': 93,\n",
       " 'pumpkin': 94,\n",
       " 'roasted_beef': 95,\n",
       " 'cottage_cheese': 96,\n",
       " 'red_wine': 97,\n",
       " 'salmon': 98,\n",
       " 'coriander': 99,\n",
       " 'coconut': 100,\n",
       " 'fenugreek': 101,\n",
       " 'starch': 102,\n",
       " 'cumin': 103,\n",
       " 'turmeric': 104,\n",
       " 'celery_oil': 105,\n",
       " 'corn': 106,\n",
       " 'cheese': 107,\n",
       " 'port_wine': 108,\n",
       " 'pecan': 109,\n",
       " 'chive': 110,\n",
       " 'apple': 111,\n",
       " 'seed': 112,\n",
       " 'tamarind': 113,\n",
       " 'tarragon': 114,\n",
       " 'sweet_potato': 115,\n",
       " 'black_bean': 116,\n",
       " 'pork_sausage': 117,\n",
       " 'berry': 118,\n",
       " 'swiss_cheese': 119,\n",
       " 'lobster': 120,\n",
       " 'parmesan_cheese': 121,\n",
       " 'crab': 122,\n",
       " 'chicken_liver': 123,\n",
       " 'veal': 124,\n",
       " 'macaroni': 125,\n",
       " 'shiitake': 126,\n",
       " 'wine': 127,\n",
       " 'buttermilk': 128,\n",
       " 'avocado': 129,\n",
       " 'fennel': 130,\n",
       " 'orange_peel': 131,\n",
       " 'orange': 132,\n",
       " 'walnut': 133,\n",
       " 'grape': 134,\n",
       " 'fruit': 135,\n",
       " 'papaya': 136,\n",
       " 'peach': 137,\n",
       " 'hazelnut': 138,\n",
       " 'shallot': 139,\n",
       " 'lime_juice': 140,\n",
       " 'grape_juice': 141,\n",
       " 'cherry': 142,\n",
       " 'blue_cheese': 143,\n",
       " 'cabbage': 144,\n",
       " 'strawberry': 145,\n",
       " 'potato_chip': 146,\n",
       " 'mango': 147,\n",
       " 'ham': 148,\n",
       " 'smoke': 149,\n",
       " 'kidney_bean': 150,\n",
       " 'feta_cheese': 151,\n",
       " 'marjoram': 152,\n",
       " 'meat': 153,\n",
       " 'rhubarb': 154,\n",
       " 'blackberry': 155,\n",
       " 'raspberry': 156,\n",
       " 'peanut_butter': 157,\n",
       " 'barley': 158,\n",
       " 'blueberry': 159,\n",
       " 'peppermint': 160,\n",
       " 'milk_fat': 161,\n",
       " 'oyster': 162,\n",
       " 'dill': 163,\n",
       " 'beet': 164,\n",
       " 'cured_pork': 165,\n",
       " 'squid': 166,\n",
       " 'turkey': 167,\n",
       " 'sage': 168,\n",
       " 'lamb': 169,\n",
       " 'goat_cheese': 170,\n",
       " 'mint': 171,\n",
       " 'mace': 172,\n",
       " 'sherry': 173,\n",
       " 'corn_flake': 174,\n",
       " 'brandy': 175,\n",
       " 'bitter_orange': 176,\n",
       " 'beer': 177,\n",
       " 'cacao': 178,\n",
       " 'bean': 179,\n",
       " 'gelatin': 180,\n",
       " 'lime': 181,\n",
       " 'beef_broth': 182,\n",
       " 'zucchini': 183,\n",
       " 'caraway': 184,\n",
       " 'red_kidney_bean': 185,\n",
       " 'cider': 186,\n",
       " 'rum': 187,\n",
       " 'brussels_sprout': 188,\n",
       " 'olive': 189,\n",
       " 'horseradish': 190,\n",
       " 'shrimp': 191,\n",
       " 'cauliflower': 192,\n",
       " 'parsnip': 193,\n",
       " 'roasted_peanut': 194,\n",
       " 'lentil': 195,\n",
       " 'cognac': 196,\n",
       " 'plum': 197,\n",
       " 'rye_flour': 198,\n",
       " 'radish': 199,\n",
       " 'whiskey': 200,\n",
       " 'sassafras': 201,\n",
       " 'turnip': 202,\n",
       " 'peanut_oil': 203,\n",
       " 'cashew': 204,\n",
       " 'mandarin': 205,\n",
       " 'gin': 206,\n",
       " 'kale': 207,\n",
       " 'tomato_juice': 208,\n",
       " 'black_mustard_seed_oil': 209,\n",
       " 'pear': 210,\n",
       " 'kiwi': 211,\n",
       " 'savory': 212,\n",
       " 'wheat_bread': 213,\n",
       " 'white_bread': 214,\n",
       " 'scallop': 215,\n",
       " 'haddock': 216,\n",
       " 'carob': 217,\n",
       " 'root': 218,\n",
       " 'leek': 219,\n",
       " 'nectarine': 220,\n",
       " 'popcorn': 221,\n",
       " 'citrus': 222,\n",
       " 'smoked_salmon': 223,\n",
       " 'liver': 224,\n",
       " 'rutabaga': 225,\n",
       " 'juniper_berry': 226,\n",
       " 'lima_bean': 227,\n",
       " 'currant': 228,\n",
       " 'brassica': 229,\n",
       " 'cereal': 230,\n",
       " 'cardamom': 231,\n",
       " 'lemon_peel': 232,\n",
       " 'rye_bread': 233,\n",
       " 'sauerkraut': 234,\n",
       " 'pistachio': 235,\n",
       " 'lavender': 236,\n",
       " 'apricot': 237,\n",
       " 'malt': 238,\n",
       " 'roasted_sesame_seed': 239,\n",
       " 'roasted_meat': 240,\n",
       " 'romano_cheese': 241,\n",
       " 'yam': 242,\n",
       " 'palm': 243,\n",
       " 'artichoke': 244,\n",
       " 'watercress': 245,\n",
       " 'coconut_oil': 246,\n",
       " 'okra': 247,\n",
       " 'saffron': 248,\n",
       " 'smoked_sausage': 249,\n",
       " 'cassava': 250,\n",
       " 'guava': 251,\n",
       " 'corn_grit': 252,\n",
       " 'roasted_pork': 253,\n",
       " 'anise': 254,\n",
       " 'lime_peel_oil': 255,\n",
       " 'rose': 256,\n",
       " 'sunflower_oil': 257,\n",
       " 'prawn': 258,\n",
       " 'anise_seed': 259,\n",
       " 'star_anise': 260,\n",
       " 'macadamia_nut': 261,\n",
       " 'provolone_cheese': 262,\n",
       " 'quince': 263,\n",
       " 'fig': 264,\n",
       " 'cherry_brandy': 265,\n",
       " 'mandarin_peel': 266,\n",
       " 'apple_brandy': 267,\n",
       " 'camembert_cheese': 268,\n",
       " 'mussel': 269,\n",
       " 'caviar': 270,\n",
       " 'chicory': 271,\n",
       " 'bourbon_whiskey': 272,\n",
       " 'endive': 273,\n",
       " 'bone_oil': 274,\n",
       " 'tequila': 275,\n",
       " 'roquefort_cheese': 276,\n",
       " 'orange_flower': 277,\n",
       " 'truffle': 278,\n",
       " 'catfish': 279,\n",
       " 'leaf': 280,\n",
       " 'chinese_cabbage': 281,\n",
       " 'seaweed': 282,\n",
       " 'sumac': 283,\n",
       " 'buckwheat': 284,\n",
       " 'peppermint_oil': 285,\n",
       " 'hop': 286,\n",
       " 'licorice': 287,\n",
       " 'tangerine': 288,\n",
       " 'sour_cherry': 289,\n",
       " 'elderberry': 290,\n",
       " 'passion_fruit': 291,\n",
       " 'octopus': 292,\n",
       " 'watermelon': 293,\n",
       " 'lingonberry': 294,\n",
       " 'violet': 295,\n",
       " 'galanga': 296,\n",
       " 'frankfurter': 297,\n",
       " 'oatmeal': 298,\n",
       " 'lemongrass': 299,\n",
       " 'mung_bean': 300,\n",
       " 'chervil': 301,\n",
       " 'pimenta': 302,\n",
       " 'prickly_pear': 303,\n",
       " 'munster_cheese': 304,\n",
       " 'wasabi': 305,\n",
       " 'baked_potato': 306,\n",
       " 'bartlett_pear': 307,\n",
       " 'chayote': 308,\n",
       " 'sour_milk': 309,\n",
       " 'durian': 310,\n",
       " 'green_tea': 311,\n",
       " 'katsuobushi': 312,\n",
       " 'pork_liver': 313,\n",
       " 'armagnac': 314,\n",
       " 'champagne_wine': 315,\n",
       " 'grape_brandy': 316,\n",
       " 'kohlrabi': 317,\n",
       " 'clove': 318,\n",
       " 'flower': 319,\n",
       " 'cabernet_sauvignon_wine': 320,\n",
       " 'gruyere_cheese': 321,\n",
       " 'mutton': 322,\n",
       " 'salmon_roe': 323,\n",
       " 'pear_brandy': 324,\n",
       " 'wood': 325,\n",
       " 'kumquat': 326,\n",
       " 'black_currant': 327,\n",
       " 'bergamot': 328,\n",
       " 'litchi': 329,\n",
       " 'chamomile': 330,\n",
       " 'beef_liver': 331,\n",
       " 'sheep_cheese': 332,\n",
       " 'holy_basil': 333,\n",
       " 'herring': 334,\n",
       " 'ouzo': 335,\n",
       " 'condiment': 336,\n",
       " 'rapeseed': 337,\n",
       " 'shellfish': 338,\n",
       " 'roasted_almond': 339,\n",
       " 'huckleberry': 340,\n",
       " 'spearmint': 341,\n",
       " 'beech': 342,\n",
       " 'blackberry_brandy': 343,\n",
       " 'jasmine_tea': 344,\n",
       " 'kelp': 345,\n",
       " 'nira': 346,\n",
       " 'enokidake': 347,\n",
       " 'mackerel': 348,\n",
       " 'eel': 349,\n",
       " 'matsutake': 350,\n",
       " 'gardenia': 351,\n",
       " 'red_bean': 352,\n",
       " 'japanese_plum': 353,\n",
       " 'black_sesame_seed': 354,\n",
       " 'artemisia': 355,\n",
       " 'citrus_peel': 356,\n",
       " 'sea_algae': 357,\n",
       " 'red_algae': 358,\n",
       " 'raw_beef': 359,\n",
       " 'kaffir_lime': 360,\n",
       " 'long_pepper': 361,\n",
       " 'strawberry_jam': 362,\n",
       " 'strawberry_juice': 363,\n",
       " 'jamaican_rum': 364,\n",
       " 'emmental_cheese': 365}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ingrs = utils.Vocabulary()\n",
    "for ingredients in df.loc[:,\"ingredients\"]:\n",
    "    for ingr in ingredients:\n",
    "        vocab_ingrs.add_word(ingr)\n",
    "vocab_ingrs.word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_cuisine = utils.Vocabulary()\n",
    "for cuisine in df.loc[:,\"cuisine\"]:\n",
    "    vocab_cuisine.add_word(cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df[\"cuisine_id\"]=vocab_cuisine.word2idx[df.loc[\"cuisine\"]]\n",
    "# class_vector=[]\n",
    "# for el in df[\"cuisine\"]:\n",
    "#     class_vector.append(vocab_cuisine.word2idx[el])\n",
    "# class_vector = torch.Tensor(class_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_INGR=max(df[\"nb_ingr\"])\n",
    "MAX_INGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingr2idx(ingr_list):\n",
    "    # If I didn't do the one-hot encoding by myself and used directly an embedding layer in the net, \n",
    "    # I would have to pad the input\n",
    "    input_=[]\n",
    "    for ingr in ingr_list:\n",
    "        input_.append(vocab_ingrs.word2idx[ingr])\n",
    "    input_ = torch.LongTensor(input_)\n",
    "    onehot_enc = F.one_hot(input_.to(torch.int64), INPUT_SIZE)\n",
    "    output = torch.sum(onehot_enc,0)\n",
    "    return output\n",
    "\n",
    "class RecipesDataset(Dataset):\n",
    "    \"\"\"Recipes dataset for cuisine classification. Only from ingredients for now\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file (string): Path to the file\n",
    "        \"\"\"\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        ingr = ingr2idx(self.data.loc[idx,\"ingredients\"])\n",
    "        label = vocab_cuisine.word2idx[self.data.loc[idx,\"cuisine\"]]\n",
    "\n",
    "        return ingr, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StratifiedSampler(Sampler):\n",
    "#     \"\"\"Stratified Sampling\n",
    "#     Provides equal representation of target classes in each batch\n",
    "#     \"\"\"\n",
    "#     def __init__(self, class_vector, batch_size):\n",
    "#         \"\"\"\n",
    "#         Arguments\n",
    "#         ---------\n",
    "#         class_vector : torch tensor\n",
    "#             a vector of class labels\n",
    "#         batch_size : integer\n",
    "#             batch_size\n",
    "#         \"\"\"\n",
    "#         self.n_splits = int(class_vector.size(0) / batch_size)\n",
    "#         self.class_vector = class_vector\n",
    "\n",
    "#     def gen_sample_array(self):\n",
    "#         try:\n",
    "#             from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#         except:\n",
    "#             print('Need scikit-learn for this functionality')\n",
    "        \n",
    "#         s = StratifiedShuffleSplit(n_splits=self.n_splits, test_size=0.2)\n",
    "#         X = th.randn(self.class_vector.size(0),2).numpy()\n",
    "#         y = self.class_vector.numpy()\n",
    "#         s.get_n_splits(X, y)\n",
    "\n",
    "#         train_index, test_index = next(s.split(X, y))\n",
    "#         return np.hstack([train_index, test_index])\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         return iter(self.gen_sample_array())\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.class_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sampleFromClass(ds, k):\n",
    "#     class_counts = {}\n",
    "#     train_data = []\n",
    "#     train_label = []\n",
    "#     test_data = []\n",
    "#     test_label = []\n",
    "#     for data, label in ds:\n",
    "#         c = label\n",
    "#         class_counts[c] = class_counts.get(c, 0) + 1\n",
    "#         if class_counts[c] <= k:\n",
    "#             train_data.append(data)\n",
    "#             train_label.append(label)\n",
    "#         else:\n",
    "#             test_data.append(data)\n",
    "#             test_label.append(label)\n",
    "#     train_data = torch.cat(train_data)\n",
    "#     for ll in train_label:\n",
    "#         print(ll)\n",
    "#     train_label = torch.cat(train_label)\n",
    "#     test_data = torch.cat(test_data)\n",
    "#     test_label = torch.cat(test_label)\n",
    "\n",
    "#     return (TensorDataset(train_data, train_label), \n",
    "#         TensorDataset(test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE=len(vocab_ingrs)\n",
    "EMBED_DIM1 = 300\n",
    "EMBED_DIM2 = 64\n",
    "NUM_CLASSES = len(vocab_cuisine) #51\n",
    "BATCH_SIZE = 1\n",
    "PRINT_FREQ = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RecipesDataset(df[[\"ingredients\",\"cuisine\"]])\n",
    "# sampler = StratifiedSampler(class_vector, BATCH_SIZE)\n",
    "train_d,test_d = torch.utils.data.random_split(dataset, [len(dataset)-1000,1000])\n",
    "# train_ds, test_ds = sampleFromClass(dataset, 5)\n",
    "train_loader = DataLoader(train_d,batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(test_d, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim1, embedding_dim2, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer_1 = nn.Linear(vocab_size, embedding_dim1, bias=True)\n",
    "        self.layer_2 = nn.Linear(embedding_dim1, embedding_dim1, bias=True)\n",
    "        self.layer_3 = nn.Linear(embedding_dim1, embedding_dim2, bias=True)\n",
    "        self.output_layer = nn.Linear(embedding_dim2, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.layer_1(x))\n",
    "        out = F.relu(self.layer_2(out))\n",
    "        out = F.relu(self.layer_3(out))\n",
    "        out = self.output_layer(out)\n",
    "        return out\n",
    "\n",
    "net = Net(INPUT_SIZE, EMBED_DIM1, EMBED_DIM2, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 3.304\n",
      "[1,  4000] loss: 2.862\n",
      "[1,  6000] loss: 2.461\n",
      "[1,  8000] loss: 2.339\n",
      "[1, 10000] loss: 2.286\n",
      "[1, 12000] loss: 2.204\n",
      "[1, 14000] loss: 2.145\n",
      "[1, 16000] loss: 2.077\n",
      "[2,  2000] loss: 2.028\n",
      "[2,  4000] loss: 2.019\n",
      "[2,  6000] loss: 1.938\n",
      "[2,  8000] loss: 1.956\n",
      "[2, 10000] loss: 1.958\n",
      "[2, 12000] loss: 1.867\n",
      "[2, 14000] loss: 1.978\n",
      "[2, 16000] loss: 1.925\n",
      "[3,  2000] loss: 1.805\n",
      "[3,  4000] loss: 1.803\n",
      "[3,  6000] loss: 1.771\n",
      "[3,  8000] loss: 1.811\n",
      "[3, 10000] loss: 1.843\n",
      "[3, 12000] loss: 1.787\n",
      "[3, 14000] loss: 1.828\n",
      "[3, 16000] loss: 1.771\n",
      "[4,  2000] loss: 1.673\n",
      "[4,  4000] loss: 1.735\n",
      "[4,  6000] loss: 1.656\n",
      "[4,  8000] loss: 1.749\n",
      "[4, 10000] loss: 1.664\n",
      "[4, 12000] loss: 1.627\n",
      "[4, 14000] loss: 1.685\n",
      "[4, 16000] loss: 1.691\n",
      "[5,  2000] loss: 1.528\n",
      "[5,  4000] loss: 1.603\n",
      "[5,  6000] loss: 1.603\n",
      "[5,  8000] loss: 1.555\n",
      "[5, 10000] loss: 1.602\n",
      "[5, 12000] loss: 1.612\n",
      "[5, 14000] loss: 1.593\n",
      "[5, 16000] loss: 1.594\n",
      "[6,  2000] loss: 1.468\n",
      "[6,  4000] loss: 1.513\n",
      "[6,  6000] loss: 1.474\n",
      "[6,  8000] loss: 1.567\n",
      "[6, 10000] loss: 1.540\n",
      "[6, 12000] loss: 1.476\n",
      "[6, 14000] loss: 1.516\n",
      "[6, 16000] loss: 1.581\n",
      "[7,  2000] loss: 1.382\n",
      "[7,  4000] loss: 1.402\n",
      "[7,  6000] loss: 1.487\n",
      "[7,  8000] loss: 1.429\n",
      "[7, 10000] loss: 1.475\n",
      "[7, 12000] loss: 1.440\n",
      "[7, 14000] loss: 1.482\n",
      "[7, 16000] loss: 1.428\n",
      "[8,  2000] loss: 1.260\n",
      "[8,  4000] loss: 1.337\n",
      "[8,  6000] loss: 1.352\n",
      "[8,  8000] loss: 1.367\n",
      "[8, 10000] loss: 1.396\n",
      "[8, 12000] loss: 1.408\n",
      "[8, 14000] loss: 1.418\n",
      "[8, 16000] loss: 1.394\n",
      "[9,  2000] loss: 1.232\n",
      "[9,  4000] loss: 1.264\n",
      "[9,  6000] loss: 1.273\n",
      "[9,  8000] loss: 1.277\n",
      "[9, 10000] loss: 1.266\n",
      "[9, 12000] loss: 1.342\n",
      "[9, 14000] loss: 1.363\n",
      "[9, 16000] loss: 1.316\n",
      "[10,  2000] loss: 1.154\n",
      "[10,  4000] loss: 1.197\n",
      "[10,  6000] loss: 1.206\n",
      "[10,  8000] loss: 1.230\n",
      "[10, 10000] loss: 1.275\n",
      "[10, 12000] loss: 1.251\n",
      "[10, 14000] loss: 1.249\n",
      "[10, 16000] loss: 1.243\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data[0]\n",
    "        labels = data[1]\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % PRINT_FREQ == PRINT_FREQ-1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test dataset: 48 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs = data[0]\n",
    "        labels = data[1]\n",
    "        outputs = net(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test dataset: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
