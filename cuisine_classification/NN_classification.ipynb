{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"D:\\\\Documents\\\\food_recipe_gen\\\\recipe_1m_analysis\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = \"D:\\\\Google Drive\\\\Catherning Folder\\\\THU\\\\Thesis\\\\Recipe datasets\\\\\"\n",
    "DATASET = [\"scirep-cuisines-detail\",\"Yummly28\"]\n",
    "FILES = [\"cleaned_data.pkl\",\"full_data.pkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>all_ingredients</th>\n",
       "      <th>american_id</th>\n",
       "      <th>nb_ingr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>[egg, yeast, wheat, milk, lard]</td>\n",
       "      <td>egg;yeast;wheat;milk;lard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[pork, carrot, pea, onion, potato]</td>\n",
       "      <td>pork;carrot;pea;onion;potato</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2</td>\n",
       "      <td>[maple_syrup]</td>\n",
       "      <td>maple_syrup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3</td>\n",
       "      <td>[wheat, yeast, almond, honey, oat, date, veget...</td>\n",
       "      <td>wheat;yeast;almond;honey;oat;date;vegetable_oi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Canada</td>\n",
       "      <td>4</td>\n",
       "      <td>[butter, lovage, clam, wheat, onion, thyme, po...</td>\n",
       "      <td>butter;lovage;clam;wheat;onion;thyme;potato;ye...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57686</td>\n",
       "      <td>57686</td>\n",
       "      <td>Italian</td>\n",
       "      <td>2453</td>\n",
       "      <td>[kiwi, olive_oil, clam, white_wine, orange, sa...</td>\n",
       "      <td>kiwi;olive_oil;clam;white_wine;orange;salmon;f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57687</td>\n",
       "      <td>57687</td>\n",
       "      <td>Italian</td>\n",
       "      <td>2454</td>\n",
       "      <td>[tomato, butter, beef, onion, red_wine, black_...</td>\n",
       "      <td>tomato;butter;beef;onion;red_wine;black_pepper...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57688</td>\n",
       "      <td>57688</td>\n",
       "      <td>Italian</td>\n",
       "      <td>2455</td>\n",
       "      <td>[vegetable, wheat, egg, cheese, olive_oil]</td>\n",
       "      <td>vegetable;wheat;egg;cheese;olive_oil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57689</td>\n",
       "      <td>57689</td>\n",
       "      <td>Italian</td>\n",
       "      <td>2456</td>\n",
       "      <td>[tomato, clam, black_pepper, parsley, celery, ...</td>\n",
       "      <td>tomato;clam;black_pepper;parsley;celery;macaroni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57690</td>\n",
       "      <td>57690</td>\n",
       "      <td>Italian</td>\n",
       "      <td>2457</td>\n",
       "      <td>[cheese, onion, bacon, black_pepper, parsley, ...</td>\n",
       "      <td>cheese;onion;bacon;black_pepper;parsley;macaro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57691 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  cuisine    id  \\\n",
       "0          0   Canada     0   \n",
       "1          1   Canada     1   \n",
       "2          2   Canada     2   \n",
       "3          3   Canada     3   \n",
       "4          4   Canada     4   \n",
       "...      ...      ...   ...   \n",
       "57686  57686  Italian  2453   \n",
       "57687  57687  Italian  2454   \n",
       "57688  57688  Italian  2455   \n",
       "57689  57689  Italian  2456   \n",
       "57690  57690  Italian  2457   \n",
       "\n",
       "                                             ingredients  \\\n",
       "0                        [egg, yeast, wheat, milk, lard]   \n",
       "1                     [pork, carrot, pea, onion, potato]   \n",
       "2                                          [maple_syrup]   \n",
       "3      [wheat, yeast, almond, honey, oat, date, veget...   \n",
       "4      [butter, lovage, clam, wheat, onion, thyme, po...   \n",
       "...                                                  ...   \n",
       "57686  [kiwi, olive_oil, clam, white_wine, orange, sa...   \n",
       "57687  [tomato, butter, beef, onion, red_wine, black_...   \n",
       "57688         [vegetable, wheat, egg, cheese, olive_oil]   \n",
       "57689  [tomato, clam, black_pepper, parsley, celery, ...   \n",
       "57690  [cheese, onion, bacon, black_pepper, parsley, ...   \n",
       "\n",
       "                                         all_ingredients  american_id  nb_ingr  \n",
       "0                              egg;yeast;wheat;milk;lard          NaN        5  \n",
       "1                           pork;carrot;pea;onion;potato          NaN        5  \n",
       "2                                            maple_syrup          NaN        1  \n",
       "3      wheat;yeast;almond;honey;oat;date;vegetable_oi...          NaN        8  \n",
       "4      butter;lovage;clam;wheat;onion;thyme;potato;ye...          NaN       16  \n",
       "...                                                  ...          ...      ...  \n",
       "57686  kiwi;olive_oil;clam;white_wine;orange;salmon;f...          NaN       17  \n",
       "57687  tomato;butter;beef;onion;red_wine;black_pepper...          NaN       11  \n",
       "57688               vegetable;wheat;egg;cheese;olive_oil          NaN        5  \n",
       "57689   tomato;clam;black_pepper;parsley;celery;macaroni          NaN        6  \n",
       "57690  cheese;onion;bacon;black_pepper;parsley;macaro...          NaN        9  \n",
       "\n",
       "[57691 rows x 7 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_pickle(os.path.join(FOLDER_PATH,DATASET[1],FILES[1]))\n",
    "df=df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'egg': 0,\n",
       " 'yeast': 1,\n",
       " 'wheat': 2,\n",
       " 'milk': 3,\n",
       " 'lard': 4,\n",
       " 'pork': 5,\n",
       " 'carrot': 6,\n",
       " 'pea': 7,\n",
       " 'onion': 8,\n",
       " 'potato': 9,\n",
       " 'maple_syrup': 10,\n",
       " 'almond': 11,\n",
       " 'honey': 12,\n",
       " 'oat': 13,\n",
       " 'date': 14,\n",
       " 'vegetable_oil': 15,\n",
       " 'whole_grain_wheat_flour': 16,\n",
       " 'butter': 17,\n",
       " 'lovage': 18,\n",
       " 'clam': 19,\n",
       " 'thyme': 20,\n",
       " 'black_pepper': 21,\n",
       " 'parsley': 22,\n",
       " 'ginger': 23,\n",
       " 'bay': 24,\n",
       " 'celery': 25,\n",
       " 'cinnamon': 26,\n",
       " 'mustard': 27,\n",
       " 'cane_molasses': 28,\n",
       " 'raisin': 29,\n",
       " 'cream': 30,\n",
       " 'asparagus': 31,\n",
       " 'olive_oil': 32,\n",
       " 'pepper': 33,\n",
       " 'garlic': 34,\n",
       " 'tomato': 35,\n",
       " 'cilantro': 36,\n",
       " 'tea': 37,\n",
       " 'jasmine': 38,\n",
       " 'vegetable': 39,\n",
       " 'brown_rice': 40,\n",
       " 'lemon_juice': 41,\n",
       " 'soy_sauce': 42,\n",
       " 'white_wine': 43,\n",
       " 'chicken': 44,\n",
       " 'vanilla': 45,\n",
       " 'rice': 46,\n",
       " 'mushroom': 47,\n",
       " 'chicken_broth': 48,\n",
       " 'basil': 49,\n",
       " 'porcini': 50,\n",
       " 'mozzarella_cheese': 51,\n",
       " 'tuna': 52,\n",
       " 'lemon': 53,\n",
       " 'beef': 54,\n",
       " 'fish': 55,\n",
       " 'cocoa': 56,\n",
       " 'green_bell_pepper': 57,\n",
       " 'oregano': 58,\n",
       " 'rosemary': 59,\n",
       " 'coffee': 60,\n",
       " 'banana': 61,\n",
       " 'squash': 62,\n",
       " 'egg_noodle': 63,\n",
       " 'bell_pepper': 64,\n",
       " 'cheddar_cheese': 65,\n",
       " 'broccoli': 66,\n",
       " 'cayenne': 67,\n",
       " 'scallion': 68,\n",
       " 'lettuce': 69,\n",
       " 'cucumber': 70,\n",
       " 'cream_cheese': 71,\n",
       " 'melon': 72,\n",
       " 'cranberry': 73,\n",
       " 'peanut': 74,\n",
       " 'nut': 75,\n",
       " 'chickpea': 76,\n",
       " 'yogurt': 77,\n",
       " 'bread': 78,\n",
       " 'tabasco_pepper': 79,\n",
       " 'cod': 80,\n",
       " 'bacon': 81,\n",
       " 'pimento': 82,\n",
       " 'black_tea': 83,\n",
       " 'grapefruit': 84,\n",
       " 'orange_juice': 85,\n",
       " 'pineapple': 86,\n",
       " 'vinegar': 87,\n",
       " 'sesame_oil': 88,\n",
       " 'sake': 89,\n",
       " 'sesame_seed': 90,\n",
       " 'soybean': 91,\n",
       " 'thai_pepper': 92,\n",
       " 'nutmeg': 93,\n",
       " 'pumpkin': 94,\n",
       " 'roasted_beef': 95,\n",
       " 'cottage_cheese': 96,\n",
       " 'red_wine': 97,\n",
       " 'salmon': 98,\n",
       " 'coriander': 99,\n",
       " 'coconut': 100,\n",
       " 'fenugreek': 101,\n",
       " 'starch': 102,\n",
       " 'cumin': 103,\n",
       " 'turmeric': 104,\n",
       " 'celery_oil': 105,\n",
       " 'corn': 106,\n",
       " 'cheese': 107,\n",
       " 'port_wine': 108,\n",
       " 'pecan': 109,\n",
       " 'chive': 110,\n",
       " 'apple': 111,\n",
       " 'seed': 112,\n",
       " 'tamarind': 113,\n",
       " 'tarragon': 114,\n",
       " 'sweet_potato': 115,\n",
       " 'black_bean': 116,\n",
       " 'pork_sausage': 117,\n",
       " 'berry': 118,\n",
       " 'swiss_cheese': 119,\n",
       " 'lobster': 120,\n",
       " 'parmesan_cheese': 121,\n",
       " 'crab': 122,\n",
       " 'chicken_liver': 123,\n",
       " 'veal': 124,\n",
       " 'macaroni': 125,\n",
       " 'shiitake': 126,\n",
       " 'wine': 127,\n",
       " 'buttermilk': 128,\n",
       " 'avocado': 129,\n",
       " 'fennel': 130,\n",
       " 'orange_peel': 131,\n",
       " 'orange': 132,\n",
       " 'walnut': 133,\n",
       " 'grape': 134,\n",
       " 'fruit': 135,\n",
       " 'papaya': 136,\n",
       " 'peach': 137,\n",
       " 'hazelnut': 138,\n",
       " 'shallot': 139,\n",
       " 'lime_juice': 140,\n",
       " 'grape_juice': 141,\n",
       " 'cherry': 142,\n",
       " 'blue_cheese': 143,\n",
       " 'cabbage': 144,\n",
       " 'strawberry': 145,\n",
       " 'potato_chip': 146,\n",
       " 'mango': 147,\n",
       " 'ham': 148,\n",
       " 'smoke': 149,\n",
       " 'kidney_bean': 150,\n",
       " 'feta_cheese': 151,\n",
       " 'marjoram': 152,\n",
       " 'meat': 153,\n",
       " 'rhubarb': 154,\n",
       " 'blackberry': 155,\n",
       " 'raspberry': 156,\n",
       " 'peanut_butter': 157,\n",
       " 'barley': 158,\n",
       " 'blueberry': 159,\n",
       " 'peppermint': 160,\n",
       " 'milk_fat': 161,\n",
       " 'oyster': 162,\n",
       " 'dill': 163,\n",
       " 'beet': 164,\n",
       " 'cured_pork': 165,\n",
       " 'squid': 166,\n",
       " 'turkey': 167,\n",
       " 'sage': 168,\n",
       " 'lamb': 169,\n",
       " 'goat_cheese': 170,\n",
       " 'mint': 171,\n",
       " 'mace': 172,\n",
       " 'sherry': 173,\n",
       " 'corn_flake': 174,\n",
       " 'brandy': 175,\n",
       " 'bitter_orange': 176,\n",
       " 'beer': 177,\n",
       " 'cacao': 178,\n",
       " 'bean': 179,\n",
       " 'gelatin': 180,\n",
       " 'lime': 181,\n",
       " 'beef_broth': 182,\n",
       " 'zucchini': 183,\n",
       " 'caraway': 184,\n",
       " 'red_kidney_bean': 185,\n",
       " 'cider': 186,\n",
       " 'rum': 187,\n",
       " 'brussels_sprout': 188,\n",
       " 'olive': 189,\n",
       " 'horseradish': 190,\n",
       " 'shrimp': 191,\n",
       " 'cauliflower': 192,\n",
       " 'parsnip': 193,\n",
       " 'roasted_peanut': 194,\n",
       " 'lentil': 195,\n",
       " 'cognac': 196,\n",
       " 'plum': 197,\n",
       " 'rye_flour': 198,\n",
       " 'radish': 199,\n",
       " 'whiskey': 200,\n",
       " 'sassafras': 201,\n",
       " 'turnip': 202,\n",
       " 'peanut_oil': 203,\n",
       " 'cashew': 204,\n",
       " 'mandarin': 205,\n",
       " 'gin': 206,\n",
       " 'kale': 207,\n",
       " 'tomato_juice': 208,\n",
       " 'black_mustard_seed_oil': 209,\n",
       " 'pear': 210,\n",
       " 'kiwi': 211,\n",
       " 'savory': 212,\n",
       " 'wheat_bread': 213,\n",
       " 'white_bread': 214,\n",
       " 'scallop': 215,\n",
       " 'haddock': 216,\n",
       " 'carob': 217,\n",
       " 'root': 218,\n",
       " 'leek': 219,\n",
       " 'nectarine': 220,\n",
       " 'popcorn': 221,\n",
       " 'citrus': 222,\n",
       " 'smoked_salmon': 223,\n",
       " 'liver': 224,\n",
       " 'rutabaga': 225,\n",
       " 'juniper_berry': 226,\n",
       " 'lima_bean': 227,\n",
       " 'currant': 228,\n",
       " 'brassica': 229,\n",
       " 'cereal': 230,\n",
       " 'cardamom': 231,\n",
       " 'lemon_peel': 232,\n",
       " 'rye_bread': 233,\n",
       " 'sauerkraut': 234,\n",
       " 'pistachio': 235,\n",
       " 'lavender': 236,\n",
       " 'apricot': 237,\n",
       " 'malt': 238,\n",
       " 'roasted_sesame_seed': 239,\n",
       " 'roasted_meat': 240,\n",
       " 'romano_cheese': 241,\n",
       " 'yam': 242,\n",
       " 'palm': 243,\n",
       " 'artichoke': 244,\n",
       " 'watercress': 245,\n",
       " 'coconut_oil': 246,\n",
       " 'okra': 247,\n",
       " 'saffron': 248,\n",
       " 'smoked_sausage': 249,\n",
       " 'cassava': 250,\n",
       " 'guava': 251,\n",
       " 'corn_grit': 252,\n",
       " 'roasted_pork': 253,\n",
       " 'anise': 254,\n",
       " 'lime_peel_oil': 255,\n",
       " 'rose': 256,\n",
       " 'sunflower_oil': 257,\n",
       " 'prawn': 258,\n",
       " 'anise_seed': 259,\n",
       " 'star_anise': 260,\n",
       " 'macadamia_nut': 261,\n",
       " 'provolone_cheese': 262,\n",
       " 'quince': 263,\n",
       " 'fig': 264,\n",
       " 'cherry_brandy': 265,\n",
       " 'mandarin_peel': 266,\n",
       " 'apple_brandy': 267,\n",
       " 'camembert_cheese': 268,\n",
       " 'mussel': 269,\n",
       " 'caviar': 270,\n",
       " 'chicory': 271,\n",
       " 'bourbon_whiskey': 272,\n",
       " 'endive': 273,\n",
       " 'bone_oil': 274,\n",
       " 'tequila': 275,\n",
       " 'roquefort_cheese': 276,\n",
       " 'orange_flower': 277,\n",
       " 'truffle': 278,\n",
       " 'catfish': 279,\n",
       " 'leaf': 280,\n",
       " 'chinese_cabbage': 281,\n",
       " 'seaweed': 282,\n",
       " 'sumac': 283,\n",
       " 'buckwheat': 284,\n",
       " 'peppermint_oil': 285,\n",
       " 'hop': 286,\n",
       " 'licorice': 287,\n",
       " 'tangerine': 288,\n",
       " 'sour_cherry': 289,\n",
       " 'elderberry': 290,\n",
       " 'passion_fruit': 291,\n",
       " 'octopus': 292,\n",
       " 'watermelon': 293,\n",
       " 'lingonberry': 294,\n",
       " 'violet': 295,\n",
       " 'galanga': 296,\n",
       " 'frankfurter': 297,\n",
       " 'sour_milk': 298,\n",
       " 'ouzo': 299,\n",
       " 'chervil': 300,\n",
       " 'balm': 301,\n",
       " 'beef_liver': 302,\n",
       " 'mung_bean': 303,\n",
       " 'green_tea': 304,\n",
       " 'wasabi': 305,\n",
       " 'litchi': 306,\n",
       " 'lemongrass': 307,\n",
       " 'huckleberry': 308,\n",
       " 'champagne_wine': 309,\n",
       " 'pear_brandy': 310,\n",
       " 'roasted_hazelnut': 311,\n",
       " 'prickly_pear': 312,\n",
       " 'bartlett_pear': 313,\n",
       " 'cabernet_sauvignon_wine': 314,\n",
       " 'wood': 315,\n",
       " 'munster_cheese': 316,\n",
       " 'bergamot': 317,\n",
       " 'mate': 318,\n",
       " 'concord_grape': 319,\n",
       " 'salmon_roe': 320,\n",
       " 'flower': 321,\n",
       " 'oatmeal': 322,\n",
       " 'kohlrabi': 323,\n",
       " 'kumquat': 324,\n",
       " 'jasmine_tea': 325,\n",
       " 'chayote': 326,\n",
       " 'condiment': 327,\n",
       " 'pork_liver': 328,\n",
       " 'black_raspberry': 329,\n",
       " 'lilac_flower_oil': 330,\n",
       " 'clove': 331,\n",
       " 'roasted_almond': 332,\n",
       " 'baked_potato': 333,\n",
       " 'angelica': 334,\n",
       " 'blackberry_brandy': 335,\n",
       " 'shellfish': 336,\n",
       " 'carnation': 337,\n",
       " 'spearmint': 338,\n",
       " 'katsuobushi': 339,\n",
       " 'soybean_oil': 340,\n",
       " 'herring': 341,\n",
       " 'black_currant': 342,\n",
       " 'mutton': 343,\n",
       " 'pimenta': 344,\n",
       " 'durian': 345,\n",
       " 'armagnac': 346,\n",
       " 'grape_brandy': 347,\n",
       " 'gruyere_cheese': 348,\n",
       " 'chamomile': 349,\n",
       " 'sheep_cheese': 350,\n",
       " 'holy_basil': 351,\n",
       " 'laurel': 352,\n",
       " 'smoked_fish': 353,\n",
       " 'sturgeon_caviar': 354,\n",
       " 'geranium': 355,\n",
       " 'pelargonium': 356,\n",
       " 'roasted_nut': 357,\n",
       " 'muscat_grape': 358,\n",
       " 'roasted_pecan': 359,\n",
       " 'rapeseed': 360,\n",
       " 'beech': 361,\n",
       " 'kelp': 362,\n",
       " 'nira': 363,\n",
       " 'enokidake': 364,\n",
       " 'mackerel': 365,\n",
       " 'eel': 366,\n",
       " 'matsutake': 367,\n",
       " 'gardenia': 368,\n",
       " 'red_bean': 369,\n",
       " 'japanese_plum': 370,\n",
       " 'black_sesame_seed': 371,\n",
       " 'artemisia': 372,\n",
       " 'citrus_peel': 373,\n",
       " 'sea_algae': 374,\n",
       " 'red_algae': 375,\n",
       " 'raw_beef': 376,\n",
       " 'kaffir_lime': 377,\n",
       " 'long_pepper': 378,\n",
       " 'strawberry_jam': 379,\n",
       " 'strawberry_juice': 380,\n",
       " 'jamaican_rum': 381,\n",
       " 'emmental_cheese': 382}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ingrs = utils.Vocabulary()\n",
    "for ingredients in df.loc[:,\"ingredients\"]:\n",
    "    for ingr in ingredients:\n",
    "        vocab_ingrs.add_word(ingr)\n",
    "vocab_ingrs.word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_cuisine = utils.Vocabulary()\n",
    "for cuisine in df.loc[:,\"cuisine\"]:\n",
    "    vocab_cuisine.add_word(cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df[\"cuisine_id\"]=vocab_cuisine.word2idx[df.loc[\"cuisine\"]]\n",
    "# class_vector=[]\n",
    "# for el in df[\"cuisine\"]:\n",
    "#     class_vector.append(vocab_cuisine.word2idx[el])\n",
    "# class_vector = torch.Tensor(class_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingr2idx(ingr_list):\n",
    "    # If I didn't do the one-hot encoding by myself and used directly an embedding layer in the net, \n",
    "    # I would have to pad the input\n",
    "    input_=[]\n",
    "    for ingr in ingr_list:\n",
    "        input_.append(vocab_ingrs.word2idx[ingr])\n",
    "    input_ = torch.LongTensor(input_)\n",
    "    onehot_enc = F.one_hot(input_.to(torch.int64), INPUT_SIZE)\n",
    "    output = torch.sum(onehot_enc,0)\n",
    "    return output\n",
    "\n",
    "class RecipesDataset(Dataset):\n",
    "    \"\"\"Recipes dataset for cuisine classification. Only from ingredients for now\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file (string): Path to the file\n",
    "        \"\"\"\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        ingr = ingr2idx(self.data.loc[idx,\"ingredients\"])\n",
    "        label = vocab_cuisine.word2idx[self.data.loc[idx,\"cuisine\"]]\n",
    "\n",
    "        return ingr, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StratifiedSampler(Sampler):\n",
    "#     \"\"\"Stratified Sampling\n",
    "#     Provides equal representation of target classes in each batch\n",
    "#     \"\"\"\n",
    "#     def __init__(self, class_vector, batch_size):\n",
    "#         \"\"\"\n",
    "#         Arguments\n",
    "#         ---------\n",
    "#         class_vector : torch tensor\n",
    "#             a vector of class labels\n",
    "#         batch_size : integer\n",
    "#             batch_size\n",
    "#         \"\"\"\n",
    "#         self.n_splits = int(class_vector.size(0) / batch_size)\n",
    "#         self.class_vector = class_vector\n",
    "\n",
    "#     def gen_sample_array(self):\n",
    "#         try:\n",
    "#             from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#         except:\n",
    "#             print('Need scikit-learn for this functionality')\n",
    "        \n",
    "#         s = StratifiedShuffleSplit(n_splits=self.n_splits, test_size=0.2)\n",
    "#         X = th.randn(self.class_vector.size(0),2).numpy()\n",
    "#         y = self.class_vector.numpy()\n",
    "#         s.get_n_splits(X, y)\n",
    "\n",
    "#         train_index, test_index = next(s.split(X, y))\n",
    "#         return np.hstack([train_index, test_index])\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         return iter(self.gen_sample_array())\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.class_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sampleFromClass(ds, k):\n",
    "#     class_counts = {}\n",
    "#     train_data = []\n",
    "#     train_label = []\n",
    "#     test_data = []\n",
    "#     test_label = []\n",
    "#     for data, label in ds:\n",
    "#         c = label\n",
    "#         class_counts[c] = class_counts.get(c, 0) + 1\n",
    "#         if class_counts[c] <= k:\n",
    "#             train_data.append(data)\n",
    "#             train_label.append(label)\n",
    "#         else:\n",
    "#             test_data.append(data)\n",
    "#             test_label.append(label)\n",
    "#     train_data = torch.cat(train_data)\n",
    "#     for ll in train_label:\n",
    "#         print(ll)\n",
    "#     train_label = torch.cat(train_label)\n",
    "#     test_data = torch.cat(test_data)\n",
    "#     test_label = torch.cat(test_label)\n",
    "\n",
    "#     return (TensorDataset(train_data, train_label), \n",
    "#         TensorDataset(test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE=len(vocab_ingrs)\n",
    "EMBED_DIM1 = 300\n",
    "EMBED_DIM2 = 64\n",
    "NUM_CLASSES = len(vocab_cuisine) #51\n",
    "BATCH_SIZE = 100\n",
    "PRINT_FREQ = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RecipesDataset(df[[\"ingredients\",\"cuisine\"]])\n",
    "# sampler = StratifiedSampler(class_vector, BATCH_SIZE)\n",
    "train_d,test_d = torch.utils.data.random_split(dataset, [len(dataset)-1000,1000])\n",
    "# train_ds, test_ds = sampleFromClass(dataset, 5)\n",
    "train_loader = DataLoader(train_d,batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(test_d, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim1, embedding_dim2, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer_1 = nn.Linear(vocab_size, embedding_dim1, bias=True)\n",
    "        self.layer_2 = nn.Linear(embedding_dim1, embedding_dim1, bias=True)\n",
    "        self.layer_3 = nn.Linear(embedding_dim1, embedding_dim2, bias=True)\n",
    "        self.output_layer = nn.Linear(embedding_dim2, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.layer_1(x))\n",
    "        out = F.relu(self.layer_2(out))\n",
    "        out = F.relu(self.layer_3(out))\n",
    "        out = self.output_layer(out)\n",
    "        return out\n",
    "\n",
    "net = Net(INPUT_SIZE, EMBED_DIM1, EMBED_DIM2, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.809\n",
      "[1,  4000] loss: 1.470\n",
      "[1,  6000] loss: 1.414\n",
      "[1,  8000] loss: 1.402\n",
      "[1, 10000] loss: 1.348\n",
      "[1, 12000] loss: 1.315\n",
      "[1, 14000] loss: 1.252\n",
      "[1, 16000] loss: 1.222\n",
      "[1, 18000] loss: 1.236\n",
      "[1, 20000] loss: 1.169\n",
      "[1, 22000] loss: 1.160\n",
      "[1, 24000] loss: 1.210\n",
      "[1, 26000] loss: 1.141\n",
      "[1, 28000] loss: 1.220\n",
      "[1, 30000] loss: 1.132\n",
      "[1, 32000] loss: 1.104\n",
      "[1, 34000] loss: 1.151\n",
      "[1, 36000] loss: 1.172\n",
      "[1, 38000] loss: 1.182\n",
      "[1, 40000] loss: 1.146\n",
      "[1, 42000] loss: 1.080\n",
      "[1, 44000] loss: 1.067\n",
      "[1, 46000] loss: 1.058\n",
      "[1, 48000] loss: 1.101\n",
      "[1, 50000] loss: 1.061\n",
      "[1, 52000] loss: 1.088\n",
      "[1, 54000] loss: 1.024\n",
      "[1, 56000] loss: 0.999\n",
      "[2,  2000] loss: 1.062\n",
      "[2,  4000] loss: 1.046\n",
      "[2,  6000] loss: 1.067\n",
      "[2,  8000] loss: 1.023\n",
      "[2, 10000] loss: 1.033\n",
      "[2, 12000] loss: 1.029\n",
      "[2, 14000] loss: 1.056\n",
      "[2, 16000] loss: 1.057\n",
      "[2, 18000] loss: 1.027\n",
      "[2, 20000] loss: 1.051\n",
      "[2, 22000] loss: 1.053\n",
      "[2, 24000] loss: 1.043\n",
      "[2, 26000] loss: 1.064\n",
      "[2, 28000] loss: 1.067\n",
      "[2, 30000] loss: 1.068\n",
      "[2, 32000] loss: 1.018\n",
      "[2, 34000] loss: 1.033\n",
      "[2, 36000] loss: 1.018\n",
      "[2, 38000] loss: 1.029\n",
      "[2, 40000] loss: 1.045\n",
      "[2, 42000] loss: 1.054\n",
      "[2, 44000] loss: 1.083\n",
      "[2, 46000] loss: 0.932\n",
      "[2, 48000] loss: 0.977\n",
      "[2, 50000] loss: 0.981\n",
      "[2, 52000] loss: 1.032\n",
      "[2, 54000] loss: 0.975\n",
      "[2, 56000] loss: 0.955\n",
      "[3,  2000] loss: 0.937\n",
      "[3,  4000] loss: 1.043\n",
      "[3,  6000] loss: 0.974\n",
      "[3,  8000] loss: 0.989\n",
      "[3, 10000] loss: 1.001\n",
      "[3, 12000] loss: 1.056\n",
      "[3, 14000] loss: 0.987\n",
      "[3, 16000] loss: 0.930\n",
      "[3, 18000] loss: 0.991\n",
      "[3, 20000] loss: 1.022\n",
      "[3, 22000] loss: 0.949\n",
      "[3, 24000] loss: 0.944\n",
      "[3, 26000] loss: 1.006\n",
      "[3, 28000] loss: 1.013\n",
      "[3, 30000] loss: 0.961\n",
      "[3, 32000] loss: 1.000\n",
      "[3, 34000] loss: 0.964\n",
      "[3, 36000] loss: 0.998\n",
      "[3, 38000] loss: 0.978\n",
      "[3, 40000] loss: 0.972\n",
      "[3, 42000] loss: 0.961\n",
      "[3, 44000] loss: 0.869\n",
      "[3, 46000] loss: 0.944\n",
      "[3, 48000] loss: 0.957\n",
      "[3, 50000] loss: 0.938\n",
      "[3, 52000] loss: 0.962\n",
      "[3, 54000] loss: 1.004\n",
      "[3, 56000] loss: 0.927\n",
      "[4,  2000] loss: 0.891\n",
      "[4,  4000] loss: 0.890\n",
      "[4,  6000] loss: 0.864\n",
      "[4,  8000] loss: 0.915\n",
      "[4, 10000] loss: 0.981\n",
      "[4, 12000] loss: 0.924\n",
      "[4, 14000] loss: 0.956\n",
      "[4, 16000] loss: 0.910\n",
      "[4, 18000] loss: 0.955\n",
      "[4, 20000] loss: 0.909\n",
      "[4, 22000] loss: 0.996\n",
      "[4, 24000] loss: 0.921\n",
      "[4, 26000] loss: 0.891\n",
      "[4, 28000] loss: 0.898\n",
      "[4, 30000] loss: 0.959\n",
      "[4, 32000] loss: 0.892\n",
      "[4, 34000] loss: 0.909\n",
      "[4, 36000] loss: 0.968\n",
      "[4, 38000] loss: 0.959\n",
      "[4, 40000] loss: 0.925\n",
      "[4, 42000] loss: 0.897\n",
      "[4, 44000] loss: 0.936\n",
      "[4, 46000] loss: 0.931\n",
      "[4, 48000] loss: 0.957\n",
      "[4, 50000] loss: 0.891\n",
      "[4, 52000] loss: 0.956\n",
      "[4, 54000] loss: 0.931\n",
      "[4, 56000] loss: 0.912\n",
      "[5,  2000] loss: 0.867\n",
      "[5,  4000] loss: 0.899\n",
      "[5,  6000] loss: 0.848\n",
      "[5,  8000] loss: 0.906\n",
      "[5, 10000] loss: 0.877\n",
      "[5, 12000] loss: 0.831\n",
      "[5, 14000] loss: 0.827\n",
      "[5, 16000] loss: 0.858\n",
      "[5, 18000] loss: 0.861\n",
      "[5, 20000] loss: 0.870\n",
      "[5, 22000] loss: 0.903\n",
      "[5, 24000] loss: 0.877\n",
      "[5, 26000] loss: 0.873\n",
      "[5, 28000] loss: 0.864\n",
      "[5, 30000] loss: 0.931\n",
      "[5, 32000] loss: 0.833\n",
      "[5, 34000] loss: 0.959\n",
      "[5, 36000] loss: 0.901\n",
      "[5, 38000] loss: 0.882\n",
      "[5, 40000] loss: 0.906\n",
      "[5, 42000] loss: 0.940\n",
      "[5, 44000] loss: 0.922\n",
      "[5, 46000] loss: 0.899\n",
      "[5, 48000] loss: 0.895\n",
      "[5, 50000] loss: 0.866\n",
      "[5, 52000] loss: 0.921\n",
      "[5, 54000] loss: 0.898\n",
      "[5, 56000] loss: 0.928\n",
      "[6,  2000] loss: 0.844\n",
      "[6,  4000] loss: 0.795\n",
      "[6,  6000] loss: 0.826\n",
      "[6,  8000] loss: 0.805\n",
      "[6, 10000] loss: 0.893\n",
      "[6, 12000] loss: 0.884\n",
      "[6, 14000] loss: 0.844\n",
      "[6, 16000] loss: 0.868\n",
      "[6, 18000] loss: 0.866\n",
      "[6, 20000] loss: 0.863\n",
      "[6, 22000] loss: 0.853\n",
      "[6, 24000] loss: 0.850\n",
      "[6, 26000] loss: 0.840\n",
      "[6, 28000] loss: 0.866\n",
      "[6, 30000] loss: 0.850\n",
      "[6, 32000] loss: 0.819\n",
      "[6, 34000] loss: 0.860\n",
      "[6, 36000] loss: 0.841\n",
      "[6, 38000] loss: 0.831\n",
      "[6, 40000] loss: 0.906\n",
      "[6, 42000] loss: 0.867\n",
      "[6, 44000] loss: 0.852\n",
      "[6, 46000] loss: 0.899\n",
      "[6, 48000] loss: 0.908\n",
      "[6, 50000] loss: 0.805\n",
      "[6, 52000] loss: 0.765\n",
      "[6, 54000] loss: 0.927\n",
      "[6, 56000] loss: 0.847\n",
      "[7,  2000] loss: 0.753\n",
      "[7,  4000] loss: 0.800\n",
      "[7,  6000] loss: 0.814\n",
      "[7,  8000] loss: 0.809\n",
      "[7, 10000] loss: 0.790\n",
      "[7, 12000] loss: 0.780\n",
      "[7, 14000] loss: 0.795\n",
      "[7, 16000] loss: 0.791\n",
      "[7, 18000] loss: 0.870\n",
      "[7, 20000] loss: 0.796\n",
      "[7, 22000] loss: 0.877\n",
      "[7, 24000] loss: 0.810\n",
      "[7, 26000] loss: 0.867\n",
      "[7, 28000] loss: 0.803\n",
      "[7, 30000] loss: 0.809\n",
      "[7, 32000] loss: 0.877\n",
      "[7, 34000] loss: 0.809\n",
      "[7, 36000] loss: 0.798\n",
      "[7, 38000] loss: 0.826\n",
      "[7, 40000] loss: 0.823\n",
      "[7, 42000] loss: 0.818\n",
      "[7, 44000] loss: 0.843\n",
      "[7, 46000] loss: 0.818\n",
      "[7, 48000] loss: 0.826\n",
      "[7, 50000] loss: 0.812\n",
      "[7, 52000] loss: 0.857\n",
      "[7, 54000] loss: 0.845\n",
      "[7, 56000] loss: 0.797\n",
      "[8,  2000] loss: 0.783\n",
      "[8,  4000] loss: 0.740\n",
      "[8,  6000] loss: 0.735\n",
      "[8,  8000] loss: 0.753\n",
      "[8, 10000] loss: 0.758\n",
      "[8, 12000] loss: 0.759\n",
      "[8, 14000] loss: 0.800\n",
      "[8, 16000] loss: 0.796\n",
      "[8, 18000] loss: 0.780\n",
      "[8, 20000] loss: 0.772\n",
      "[8, 22000] loss: 0.769\n",
      "[8, 24000] loss: 0.765\n",
      "[8, 26000] loss: 0.763\n",
      "[8, 28000] loss: 0.753\n",
      "[8, 30000] loss: 0.846\n",
      "[8, 32000] loss: 0.788\n",
      "[8, 34000] loss: 0.796\n",
      "[8, 36000] loss: 0.795\n",
      "[8, 38000] loss: 0.779\n",
      "[8, 40000] loss: 0.863\n",
      "[8, 42000] loss: 0.848\n",
      "[8, 44000] loss: 0.800\n",
      "[8, 46000] loss: 0.813\n",
      "[8, 48000] loss: 0.833\n",
      "[8, 50000] loss: 0.766\n",
      "[8, 52000] loss: 0.831\n",
      "[8, 54000] loss: 0.800\n",
      "[8, 56000] loss: 0.783\n",
      "[9,  2000] loss: 0.738\n",
      "[9,  4000] loss: 0.712\n",
      "[9,  6000] loss: 0.736\n",
      "[9,  8000] loss: 0.724\n",
      "[9, 10000] loss: 0.807\n",
      "[9, 12000] loss: 0.737\n",
      "[9, 14000] loss: 0.708\n",
      "[9, 16000] loss: 0.804\n",
      "[9, 18000] loss: 0.772\n",
      "[9, 20000] loss: 0.706\n",
      "[9, 22000] loss: 0.726\n",
      "[9, 24000] loss: 0.729\n",
      "[9, 26000] loss: 0.738\n",
      "[9, 28000] loss: 0.773\n",
      "[9, 30000] loss: 0.762\n",
      "[9, 32000] loss: 0.800\n",
      "[9, 34000] loss: 0.745\n",
      "[9, 36000] loss: 0.755\n",
      "[9, 38000] loss: 0.749\n",
      "[9, 40000] loss: 0.760\n",
      "[9, 42000] loss: 0.724\n",
      "[9, 44000] loss: 0.827\n",
      "[9, 46000] loss: 0.748\n",
      "[9, 48000] loss: 0.805\n",
      "[9, 50000] loss: 0.775\n",
      "[9, 52000] loss: 0.753\n",
      "[9, 54000] loss: 0.808\n",
      "[9, 56000] loss: 0.753\n",
      "[10,  2000] loss: 0.680\n",
      "[10,  4000] loss: 0.690\n",
      "[10,  6000] loss: 0.696\n",
      "[10,  8000] loss: 0.692\n",
      "[10, 10000] loss: 0.668\n",
      "[10, 12000] loss: 0.704\n",
      "[10, 14000] loss: 0.738\n",
      "[10, 16000] loss: 0.757\n",
      "[10, 18000] loss: 0.740\n",
      "[10, 20000] loss: 0.665\n",
      "[10, 22000] loss: 0.698\n",
      "[10, 24000] loss: 0.707\n",
      "[10, 26000] loss: 0.707\n",
      "[10, 28000] loss: 0.744\n",
      "[10, 30000] loss: 0.737\n",
      "[10, 32000] loss: 0.773\n",
      "[10, 34000] loss: 0.778\n",
      "[10, 36000] loss: 0.736\n",
      "[10, 38000] loss: 0.696\n",
      "[10, 40000] loss: 0.734\n",
      "[10, 42000] loss: 0.711\n",
      "[10, 44000] loss: 0.709\n",
      "[10, 46000] loss: 0.719\n",
      "[10, 48000] loss: 0.695\n",
      "[10, 50000] loss: 0.776\n",
      "[10, 52000] loss: 0.748\n",
      "[10, 54000] loss: 0.809\n",
      "[10, 56000] loss: 0.782\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data[0]\n",
    "        labels = data[1]\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % PRINT_FREQ == PRINT_FREQ-1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test dataset: 73 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs = data[0]\n",
    "        labels = data[1]\n",
    "        outputs = net(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test dataset: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
