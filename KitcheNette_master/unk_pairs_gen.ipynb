{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(os.getcwd(),os.pardir))\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "from recipe_gen.seq2seq_utils import FOLDER_PATH, DATA_FILES\n",
    "from recipe_1m_analysis.utils import Vocabulary\n",
    "import recipe_1m_analysis.ingr_normalization as ingr_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_file = os.path.join(os.getcwd(),\"KitcheNette_master\",\"data\",\"kitchenette_pairing_scores.csv\")\n",
    "with open(os.path.join(known_file),'rb') as f:\n",
    "    known_pairs=pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_dict = {}\n",
    "count_e=0\n",
    "for row_idx, row in known_pairs.iterrows():\n",
    "    try:\n",
    "        ingr1_n = ingr_norm.normalize_ingredient(row[\"ingr1\"])\n",
    "        ingr2_n = ingr_norm.normalize_ingredient(row[\"ingr2\"])\n",
    "        known_dict[frozenset((ingr1_n.name,ingr2_n.name))]=row[\"npmi\"]\n",
    "    except AttributeError:\n",
    "        count_e+=1\n",
    "\n",
    "print(f\"Removed {count_e} false pairings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(FOLDER_PATH,DATA_FILES[3]),'rb') as f:\n",
    "    vocab_ingrs=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_main_ingr = Vocabulary()\n",
    "for k,v in vocab_ingrs.idx2word.items():\n",
    "    main_ingr=None\n",
    "    min_len=100\n",
    "    for ingr in v:\n",
    "        if len(ingr.split(\"_\"))<min_len:\n",
    "            main_ingr = ingr\n",
    "            min_len = len(ingr.split(\"_\"))\n",
    "    try:\n",
    "        vocab_main_ingr.add_word(ingr_norm.normalize_ingredient(main_ingr).name,k)\n",
    "    except:\n",
    "        print(main_ingr)\n",
    "\n",
    "#TODO: remove special tokens sos, eos, pad, unk more properly\n",
    "del vocab_main_ingr.word2idx[\"<\"]\n",
    "del vocab_main_ingr.idx2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ingr = list(vocab_main_ingr.word2idx.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('main_pairing_prediction.csv', mode='w',newline='') as f:\n",
    "    csvwriter = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csvwriter.writerow([\"ingr1\",\"ingr2\"])\n",
    "    for i,ingr1 in enumerate(list_ingr):\n",
    "        for ingr2 in list_ingr[i+1:]:\n",
    "            if frozenset((ingr1,ingr2)) not in known_dict:\n",
    "                csvwriter.writerow([ingr1,ingr2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
